{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_GAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"5s4EcwwZbnwc","colab_type":"text"},"cell_type":"markdown","source":["# Keras-GAN\n","This is a basic implementation of GAN inspired by [Keras-GAN](https://github.com/eriklindernoren/Keras-GAN)"]},{"metadata":{"id":"BxgzddUsvQm7","colab_type":"text"},"cell_type":"markdown","source":["Inspired by [GAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py),\n","[DCGAN](https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py),\n","[DCGAN by fchaollet](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/8.5-introduction-to-gans.ipynb#scrollTo=WLCF7I8opN7i), [DCGAN from TF with eager](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb)\n"]},{"metadata":{"id":"_uqHIKr1NzXv","colab_type":"text"},"cell_type":"markdown","source":["GANs use cases:\n","\n","\n","*   Upscale images\n","*   Infer the next frames in videos\n","*   Transform simplistic drawings into photorealistic sceneries\n","*   \n","\n"]},{"metadata":{"colab_type":"code","id":"RZn1TNpMwTa6","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"95bb019d-e8fe-463f-df77-862c6b19c459","executionInfo":{"status":"ok","timestamp":1547397639263,"user_tz":300,"elapsed":3504,"user":{"displayName":"Ali Panahi","photoUrl":"https://lh5.googleusercontent.com/-aAEVDWwWDxU/AAAAAAAAAAI/AAAAAAAAEuM/WOpI1BZp8tM/s64/photo.jpg","userId":"09333706783536538061"}}},"cell_type":"code","source":["# Install Dependencies\n","!pip install tensorboardcolab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"}]},{"metadata":{"id":"i_3TMxr-t99K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"21612050-7c78-44b4-ff0a-3455a6a62bd9","executionInfo":{"status":"ok","timestamp":1547400014142,"user_tz":300,"elapsed":264,"user":{"displayName":"Ali Panahi","photoUrl":"https://lh5.googleusercontent.com/-aAEVDWwWDxU/AAAAAAAAAAI/AAAAAAAAEuM/WOpI1BZp8tM/s64/photo.jpg","userId":"09333706783536538061"}}},"cell_type":"code","source":["#List available Devices\n","# from tensorflow.python.client import device_lib\n","# device_lib.list_local_devices()\n","# Check Versions\n","import tensorflow\n","import keras\n","print(tensorflow.__version__)\n","print(tensorflow.keras.__version__)\n","print(keras.__version__)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["1.12.0\n","2.1.6-tf\n","2.2.4\n"],"name":"stdout"}]},{"metadata":{"id":"GnzU3rfvt-0s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"c0f4dc48-4704-41e1-ad81-f78dbeaa6ea1","executionInfo":{"status":"ok","timestamp":1547399776069,"user_tz":300,"elapsed":11995,"user":{"displayName":"Ali Panahi","photoUrl":"https://lh5.googleusercontent.com/-aAEVDWwWDxU/AAAAAAAAAAI/AAAAAAAAEuM/WOpI1BZp8tM/s64/photo.jpg","userId":"09333706783536538061"}}},"cell_type":"code","source":["# Run Tensorboard\n","from tensorboardcolab import *\n","tbc=TensorBoardColab()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://dfa3d666.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"4oFYutic3pLe","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import libraries\n","from __future__ import print_function, division\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import TensorBoard\n","import matplotlib.pyplot as plt\n","from tensorflow.python.keras import models\n","\n","\n","import sys\n","import os\n","import time\n","\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C_oFjjxH4LMe","colab_type":"text"},"cell_type":"markdown","source":["The process is as follows:\n","\n","  \n"]},{"metadata":{"id":"kkKsmDSucJu6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1816},"outputId":"a63c2f58-af91-4308-b4a1-d70e18ff526f","executionInfo":{"status":"error","timestamp":1547400201633,"user_tz":300,"elapsed":10405,"user":{"displayName":"Ali Panahi","photoUrl":"https://lh5.googleusercontent.com/-aAEVDWwWDxU/AAAAAAAAAAI/AAAAAAAAEuM/WOpI1BZp8tM/s64/photo.jpg","userId":"09333706783536538061"}}},"cell_type":"code","source":["class GAN:\n","  def __init__(self, image_path):\n","    device = self.best_available_device()\n","    self.image_path = image_path\n","    self.img_rows = 28\n","    self.img_cols = 28\n","    self.channels = 1\n","    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","    self.latent_dim = 100\n","\n","    optimizer = Adam(0.0002, 0.5)\n","\n","    # Build and compile the discriminator\n","    self.discriminator_cpu_gpu = self.build_discriminator()\n","    print('Sequential', isinstance(self.discriminator_cpu_gpu, Sequential))\n","    print('Model', isinstance(self.discriminator_cpu_gpu, Model))\n","    model = models.clone_model(self.discriminator_cpu_gpu)\n","    print('Sequential Cloned', isinstance(model, Sequential))\n","    print('Model Cloned', isinstance(model, Model))\n","    \n","    if device == 'tpu':\n","      self.discriminator = tf.contrib.tpu.keras_to_tpu_model(\n","          self.discriminator_cpu_gpu,\n","          strategy=tf.contrib.tpu.TPUDistributionStrategy(\n","              tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","          )\n","      )\n","    else:\n","      self.discriminator = self.discriminator_cpu_gpu\n","    \n","    self.discriminator.compile(loss='binary_crossentropy',\n","      optimizer=optimizer,\n","      metrics=['accuracy'])\n","\n","    # Build the generator\n","    self.generator = self.build_generator()\n","\n","    # The generator takes noise as input and generates imgs\n","    z = Input(shape=(self.latent_dim,))\n","    img = self.generator(z)\n","\n","    # For the combined model we will only train the generator\n","    self.discriminator_frozen = Model(inputs=self.discriminator_cpu_gpu.inputs,\n","                      outputs=self.discriminator_cpu_gpu.outputs)\n","    self.discriminator_frozen.trainable = False\n","\n","    # The discriminator takes generated images as input and determines validity\n","    validity = self.discriminator_frozen(img)\n","\n","    # The combined model  (stacked generator and discriminator)\n","    # Trains the generator to fool the discriminator\n","    self.combined_cpu_gpu = Model(inputs=z, outputs=validity)\n","    \n","    if device == 'tpu':\n","      self.combined = tf.contrib.tpu.keras_to_tpu_model(\n","          self.combined_cpu_gpu,\n","          strategy=tf.contrib.tpu.TPUDistributionStrategy(\n","              tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","          )\n","      )\n","    else:\n","      self.combined = self.combined_cpu_gpu\n","      \n","    self.combined.compile(loss='binary_crossentropy',\n","      optimizer=optimizer,\n","      metrics=['accuracy'])\n","\n","\n","  def build_generator(self):\n","\n","    model = Sequential()\n","\n","    model.add(Dense(256, input_dim=self.latent_dim))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(1024))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","    model.add(Reshape(self.img_shape))\n","\n","\n","    noise = Input(shape=(self.latent_dim,))\n","    img = model(noise)\n","\n","    return Model(inputs=noise, outputs=img)\n","\n","  def build_discriminator(self):\n","\n","    model = Sequential()\n","\n","    model.add(Flatten(input_shape=self.img_shape))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(256))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    img = Input(shape=self.img_shape)\n","    validity = model(img)\n","\n","    return Model(inputs=img, outputs=validity)\n","\n","  def train(self, epochs, batch_size=128, sample_interval=50):\n","    if False:\n","      print('Generator Model:')\n","      self.discriminator.summary()\n","      print('Discriminator Model:')\n","      self.combined.summary()\n","\n","    # Load the dataset\n","    (X_train, _), (_, _) = mnist.load_data()\n","    \n","    # Rescale -1 to 1\n","    X_train = X_train / 127.5 - 1.\n","    X_train = np.expand_dims(X_train, axis=3)\n","\n","    # Adversarial ground truths\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","\n","    # Setup tensorboard\n","    # Create the TensorBoard callback,\n","    # which we will drive manually\n","    now = time.time()\n","    tensorboard_d = TensorBoard(\n","      log_dir= f'./Graph/{now}/d',\n","      histogram_freq=0,\n","      batch_size=batch_size,\n","      write_graph=True,\n","      write_grads=True\n","    )\n","    tensorboard_g = TensorBoard(\n","      log_dir= f'./Graph/{now}/g',\n","      histogram_freq=0,\n","      batch_size=batch_size,\n","      write_graph=True,\n","      write_grads=True\n","    )\n","    \n","    tensorboard_d.set_model(self.discriminator)\n","    tensorboard_g.set_model(self.combined)\n","    \n","    for epoch in range(epochs):\n","\n","      # ---------------------\n","      #  Train Discriminator\n","      # ---------------------\n","\n","      # Generate a batch of new images\n","      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","      gen_imgs = self.generator.predict(noise)\n","      \n","      # Select a random batch of images\n","      idx = np.random.randint(0, X_train.shape[0], batch_size)\n","      imgs = X_train[idx]\n","\n","\n","      # Train the discriminator\n","      d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","      # ---------------------\n","      #  Train Generator\n","      # ---------------------\n","\n","      noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","      # Train the generator (to have the discriminator label samples as valid)\n","      g_loss = self.combined.train_on_batch(noise, valid)\n","\n","      # Plot the progress\n","      # print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], g_loss[1]))\n","      tensorboard_d.on_epoch_end(epoch, self.named_logs(self.discriminator, d_loss))\n","      tensorboard_g.on_epoch_end(epoch, self.named_logs(self.combined, g_loss))\n","      # If at save interval => save generated image samples\n","      if epoch % sample_interval == 0:\n","        print(f'epoch: {epoch}')\n","        self.sample_images(epoch)\n","    \n","    tensorboard_d.on_train_end(None)\n","    tensorboard_g.on_train_end(None)\n","\n","  def sample_images(self, epoch):\n","    r, c = 5, 5\n","    noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","    gen_imgs = self.generator.predict(noise)\n","\n","    # Rescale images 0 - 1\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","      for j in range(c):\n","        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","        axs[i,j].axis('off')\n","        cnt += 1\n","    fig.savefig(self.image_path + \"%d.png\" % epoch)\n","    plt.close()\n","  \n","  # Transform train_on_batch return value\n","  # to dict expected by on_batch_end callback\n","  def named_logs(self, model, logs):\n","    result = {}\n","    for metric_name, log_value in zip(model.metrics_names, logs):\n","      result[metric_name] = log_value\n","    return result\n","\n","  def best_available_device(self):\n","    gpu_available = tf.test.is_gpu_available()\n","    tpu_available = 'COLAB_TPU_ADDR' in os.environ\n","    if tpu_available:\n","      return 'tpu'\n","    elif gpu_available:\n","      return 'gpu'\n","    else:\n","      return 'cpu'\n","    \n","if __name__ == '__main__':\n","  image_path = './imgs/'\n","  if not os.path.exists(image_path):\n","    os.makedirs(image_path)\n","  gan = GAN(image_path)\n","  gan.train(epochs=5001, batch_size=32, sample_interval=500)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Sequential False\n","Model True\n","Sequential Cloned False\n","Model Cloned True\n","INFO:tensorflow:Querying Tensorflow master (b'grpc://10.68.193.138:8470') for TPU system metadata.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2386358207207873321)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14191721723296006097)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 5771321573470959913)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6329731057825049777)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4094911016392389456)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17078341087934467489)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8818774545091808753)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18009122152072346722)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13060524171902296009)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2043674857271677299)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4603214757091026063)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9151328406356428136)\n","WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n","INFO:tensorflow:Cloning Adam {'lr': 0.00019999999494757503, 'beta_1': 0.5, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","INFO:tensorflow:Querying Tensorflow master (b'grpc://10.68.193.138:8470') for TPU system metadata.\n","INFO:tensorflow:Found TPU system:\n","INFO:tensorflow:*** Num TPU Cores: 8\n","INFO:tensorflow:*** Num TPU Workers: 1\n","INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2386358207207873321)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14191721723296006097)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 5771321573470959913)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6329731057825049777)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4094911016392389456)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17078341087934467489)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8818774545091808753)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18009122152072346722)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13060524171902296009)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2043674857271677299)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4603214757091026063)\n","INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9151328406356428136)\n","WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n","INFO:tensorflow:Cloning Adam {'lr': 0.00019999999494757503, 'beta_1': 0.5, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 28, 28, 1), dtype=tf.float32, name='input_2_30'), TensorSpec(shape=(4, 1), dtype=tf.float32, name='sequential_1_target_10')]\n","INFO:tensorflow:Overriding default placeholder.\n","INFO:tensorflow:Cloning Adam {'lr': 0.00019999999494757503, 'beta_1': 0.5, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n","INFO:tensorflow:Remapping placeholder for input_2\n","INFO:tensorflow:Remapping placeholder for flatten_1_input\n","INFO:tensorflow:Default: flatten_1_input\n","ERROR:tensorflow:Operation of type Placeholder (tpu_140308805199352/flatten_1_input) is not supported on the TPU. Execution will fail if this op is used in the graph. \n","INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f9c2eab5470> []\n","INFO:tensorflow:Started compiling\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-cd11f512a028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-cd11f512a028>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m       \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0minput_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfeed_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_input_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     tpu_model_ops = self._tpu_model_ops_for_input_specs(input_specs,\n\u001b[0;32m-> 1249\u001b[0;31m                                                         infeed_manager)\n\u001b[0m\u001b[1;32m   1250\u001b[0m     \u001b[0minfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfeed_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_model_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m_tpu_model_ops_for_input_specs\u001b[0;34m(self, input_specs, infeed_manager)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                                                  infeed_manager)\n\u001b[1;32m   1155\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compilation_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_tpu_model_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_model_compiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tpu_model_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compilation_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m_test_model_compiles\u001b[0;34m(self, tpu_model_ops)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_error_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m       raise RuntimeError('Compilation failed: {}'.format(\n\u001b[0;32m-> 1099\u001b[0;31m           proto.status_error_message))\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Compilation failed: Compilation failure: Detected unsupported operations when trying to compile graph cluster_9786834973823077564[] on XLA_TPU_JIT: Placeholder (No registered 'Placeholder' OpKernel for XLA_TPU_JIT devices compatible with node {{node tpu_140308805199352/flatten_1_input}} = Placeholder[dtype=DT_FLOAT, shape=[?,28,28,1], _device=\"/device:TPU_REPLICATED_CORE\"]()\n\t.  Registered:  device='TPU'\n  device='CPU'\n  device='GPU'\n  device='XLA_GPU'\n  device='XLA_CPU'\n){{node tpu_140308805199352/flatten_1_input}}"]}]},{"metadata":{"id":"G33nw5QnQHNy","colab_type":"text"},"cell_type":"markdown","source":["# How GAN works\n","- for each epoch:\n","  1. generator.predict\n","  2. discriminator.train_on_batch\n","  3. combo_frozen_discriminator.train_on_batch \n","\n","- for each epoch:\n","  1.   Generator creates fake images\n","  2.   Discriminator learns how to distinguish these fake images with real images\n","  3.   Generator learns how to create better fake images using Discriminator guides ${\\frac{p_{data}(x)}{  p_{model}(x)}}$\n","\n","Generator generate images that discrimintator cannot distinguish => combo low score!\n","\n","\n","---\n","\n","\n","Theoretical perfect final state:\n","-   Have 100% accuracy for the generator - meaning the discriminator classifies all synthetic observations as real;\n","-   Have about 50% accuracy for the discriminator - meaning it cannot distingiush fake observations from real ones;\n","-   The synthetic observations are of good quality.\n","\n","\n","\n","---\n","\n","How they should evolve:\n","-   Discriminator: Start from ~50% goes to ~100% very fast and comes back to 50%\n","-   Generator: Starts from ~0% and goes to ~100% acc"]},{"metadata":{"id":"WpH3D3REQOHP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Pseduo Code, NOT A RUNNABLE CELL.\n","The process is as follows:\n","init()\n","    # Build and compile the discriminator\n","    discriminator = build_discriminator() {\n","      model = Sequential()\n","      model.add()\n","      img_generator_output = Input(shape=self.img_shape)\n","      validity = model(img_generator_output)\n","      return Model(inputs=img_generator_output, outputs=validity)\n","    }\n","    discriminator.compile()\n","\n","    # Build the generator\n","    generator = build_generator() {\n","      model = Sequential()\n","      model.add()\n","      noise = Input(shape=(self.latent_dim,))\n","      img_generator_output = model(noise)\n","      return Model(inputs=noise, outputs=img_generator_output)\n","    }\n","     # The generator takes noise as input and generates imgs\n","    z_generator_input_noise = Input(shape=(self.latent_dim,))\n","    img_generator_output = generator(z_generator_input_noise)\n","\n","    discriminator.trainable = False;\n","    validity_discriminator_output = self.discriminator_frozen(img_generator_output)\n","\n","    self.combined = Model(inputs=z_generator_input_noise, outputs=validity_discriminator_output)\n","\n","\n","gan.train()\n","  # Load the dataset X_train\n","  # Rescale -1 to 1\n","  # set Adversarial Y_valid = np.ones and Y_fake = np.zeros\n","  for epoch in range(epochs):\n","    # Generate a batch of new images\n","    gen_imgs = self.generator.predict(noise)\n","\n","    # ***Discriminator Training***\n","    # Select a random batch of images\n","    # Train the discriminator\n","    # Ali: Would it help if I combine the real_imgs and the gen_imgs and then do one train_on_batch.\n","      d_loss_real = self.discriminator.train_on_batch(real_imgs, Y_valid)\n","      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, Y_fake)\n","      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","    # Now the discriminator knows how to classify fake images from true ones\n","\n","    # ***Generator Training***\n","    # Train the generator in combined (to have the discriminator label samples as Y_valid)\n","      g_loss = self.combined.train_on_batch(noise, Y_valid)\n","\n","    # If at save interval => save generated image samples\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D_NQljz2Tm9k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"5e33f015-481f-4951-b3db-29c1530aae64","executionInfo":{"status":"ok","timestamp":1547390666677,"user_tz":300,"elapsed":23030,"user":{"displayName":"Ali Panahi","photoUrl":"https://lh5.googleusercontent.com/-aAEVDWwWDxU/AAAAAAAAAAI/AAAAAAAAEuM/WOpI1BZp8tM/s64/photo.jpg","userId":"09333706783536538061"}}},"cell_type":"code","source":["!pip install tensorboardcolab\n","from tensorboardcolab import *\n","tbc=TensorBoardColab()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://b3806594.ngrok.io\n"],"name":"stdout"}]},{"metadata":{"id":"GXjzY6MeY7Ns","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}